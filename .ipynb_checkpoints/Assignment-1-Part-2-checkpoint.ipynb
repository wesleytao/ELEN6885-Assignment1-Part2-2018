{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ELEN 6885 Reinforcement Learning coding assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your code should remain in the block marked by<br />\n",
    "\\############################<br />\n",
    "\\# YOUR CODE STARTS HERE<br />\n",
    "\\# YOUR CODE ENDS HERE<br />\n",
    "\\############################<br />\n",
    "Please don't edit anything outside the block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "% load_ext autoreload\n",
    "% autoreload 2\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import gym"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Incremental Implementation of Average\n",
    "We've finished the incremental implementation of average for you. Please call the function estimate with 1/step step size and fixed step size to compare the difference between this two on a simulated Bandit problem.<br />\n",
    "<span style=\"color:red\">(2 pts)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RLalgs is a package containing Reinforcement Learning algorithms Epsilon-Greedy, Policy Iteration, Value Iteration, Q-Learning, and SARSA.\n"
     ]
    }
   ],
   "source": [
    "from RLalgs.utils import estimate\n",
    "random.seed(6885)\n",
    "numTimeStep = 10000\n",
    "q_h = np.zeros(numTimeStep + 1) # Q Value estimate with 1/step step size\n",
    "q_f = np.zeros(numTimeStep + 1) # Q value estimate with fixed step size\n",
    "FixedStepSize = 0.5 #A large number to exaggerate the difference\n",
    "for step in range(1, numTimeStep + 1):\n",
    "    if step < numTimeStep / 2:\n",
    "        r = random.gauss(mu = 1, sigma = 0.1)\n",
    "    else:\n",
    "        r = random.gauss(mu = 3, sigma = 0.1)\n",
    "    \n",
    "    #TIPS: Call function estimate defined in ./RLalgs/utils.py\n",
    "    ############################\n",
    "    # YOUR CODE STARTS HERE\n",
    "    q_h[step] = q_h[step-1] + (1/step)*(r-q_h[step-1])\n",
    "    q_f[step] = q_h[step-1] + FixedStepSize*(r-q_h[step-1])\n",
    "    # YOUR CODE ENDS HERE\n",
    "    ############################\n",
    "    \n",
    "q_h = q_h[1:]\n",
    "q_f = q_f[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the two Q value estimates. (Please include a title, labels on both axes, and legends)<br />\n",
    "<span style=\"color:red\">(3 pts)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x268a6b99358>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "############################\n",
    "# YOUR CODE STARTS HERE\n",
    "plt.plot(q_h,label = '1/n step size')\n",
    "plt.plot(q_f, label = 'constant step size')\n",
    "plt.xlabel(\"step size\")\n",
    "plt.ylabel(\"Q value\")\n",
    "plt.title(\"n arm bandit problem\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "# YOUR CODE ENDS HERE\n",
    "############################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. $\\epsilon$-Greedy for Exploration\n",
    "In Reinforcement Learning, we are always faced with the dilemma of exploration and exploitation. $\\epsilon$-Greedy is a trade-off between them. You are gonna implement Greedy and $\\epsilon$-Greedy. We combine these two policies in one function by treating Greedy as $\\epsilon$-Greedy where $\\epsilon = 0$. Edit the function epsilon_greedy in ./RLalgs/utils.py.<br />\n",
    "<span style=\"color:red\">(5 pts)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values:\n",
      "[ 0.61264537  0.27923079 -0.84600857  0.05469574 -1.09990968]\n",
      "Greedy Choice = 0\n",
      "Epsilon-Greedy Choice = 0\n"
     ]
    }
   ],
   "source": [
    "from RLalgs.utils import epsilon_greedy\n",
    "np.random.seed(6885) #Set the seed to cancel the randomness\n",
    "q = np.random.normal(0, 1, size = 5)\n",
    "############################\n",
    "# YOUR CODE STARTS HERE\n",
    "greedy_action = epsilon_greedy(q,0) #Use epsilon = 0 for Greedy\n",
    "e_greedy_action = epsilon_greedy(q,0.1) #Use epsilon = 0.1\n",
    "# YOUR CODE ENDS HERE\n",
    "############################\n",
    "print('Values:')\n",
    "print(q)\n",
    "print('Greedy Choice =', greedy_action)\n",
    "print('Epsilon-Greedy Choice =', e_greedy_action)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should get the following results.<br />\n",
    "Values:<br />\n",
    "\\[ 0.61264537  0.27923079 -0.84600857  0.05469574 -1.09990968\\]<br />\n",
    "Greedy Choice = 0<br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Frozen Lake Environment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('FrozenLake-v0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Derive Q value from V value\n",
    "Edit function action_evaluation in ./RLalgs/utils.py.<br />\n",
    "TIPS: $q(s, a)=\\sum_{s',r}p(s',r|s,a)(r+\\gamma v(s'))$<br />\n",
    "<span style=\"color:red\">(5 pts)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action values:\n",
      "[[1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.        ]\n",
      " [1.         1.33333333 1.33333333 1.33333333]\n",
      " [1.         1.         1.         1.        ]]\n"
     ]
    }
   ],
   "source": [
    "from RLalgs.utils import action_evaluation\n",
    "v = np.ones(16)\n",
    "q = action_evaluation(env = env.env, gamma = 1, v = v)\n",
    "print('Action values:')\n",
    "print(q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should get Q values all equal to one except at State 14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pseudo-codes of the following four algorithms can be found on Page 80, 83, 130, 131 of the Sutton's book."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Model-based RL algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from RLalgs.utils import action_evaluation, action_selection, render"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1 Policy Iteration\n",
    "Edit the function policy_iteration and relevant functions in ./RLalgs/pi.py to implement the Policy Iteration Algorithm.<br />\n",
    "<span style=\"color:red\">(15 pts)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State values:\n",
      "[0.82352774 0.8235272  0.82352682 0.82352662 0.82352791 0.\n",
      " 0.52941063 0.         0.82352817 0.82352851 0.76470509 0.\n",
      " 0.         0.88235232 0.94117615 0.        ]\n",
      "Number of iterations to converge = 7\n"
     ]
    }
   ],
   "source": [
    "from RLalgs.pi import policy_iteration\n",
    "V, policy, numIterations = policy_iteration(env = env.env, gamma = 1, max_iteration = 500, theta = 1e-7)\n",
    "print('State values:')\n",
    "print(V)\n",
    "print('Number of iterations to converge =', numIterations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should get values close to:<br />\n",
    "State values:<br />\n",
    "\\[0.82352774 0.8235272  0.82352682 0.82352662 0.82352791 0.<br />\n",
    "0.52941063 0.         0.82352817 0.82352851 0.76470509 0.<br />0.         0.88235232 0.94117615 0.\\]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Uncomment and run the following to evaluate your result, comment them when you generate the pdf\n",
    "# Q = action_evaluation(env = env.env, gamma = 1, v = V)\n",
    "# policy_estimate = action_selection(Q)\n",
    "# render(env, policy_estimate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2 Value Iteration\n",
    "Edit the function value_iteration and relevant functions in ./RLalgs/vi.py to implement the Value Iteration Algorithm.<br />\n",
    "<span style=\"color:red\">(10 pts)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State values:\n",
      "[0.82352773 0.82352718 0.8235268  0.8235266  0.8235279  0.\n",
      " 0.52941062 0.         0.82352816 0.8235285  0.76470509 0.\n",
      " 0.         0.88235231 0.94117615 0.        ]\n",
      "Number of iterations to converge = 389\n"
     ]
    }
   ],
   "source": [
    "from RLalgs.vi import value_iteration\n",
    "V, policy, numIterations = value_iteration(env = env.env, gamma = 1, max_iteration = 500, theta = 1e-7)\n",
    "print('State values:')\n",
    "print(V)\n",
    "print('Number of iterations to converge =', numIterations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should get values close to:<br />\n",
    "State values:<br />\n",
    "\\[0.82352773 0.82352718  0.8235268 0.8235266 0.8235279 0.<br />\n",
    "0.52941062 0.         0.82352816 0.8235285 0.76470509 0.<br />0.         0.88235231 0.94117615 0.\\]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Uncomment and run the following to evaluate your result, comment them when you generate the pdf\n",
    "# Q = action_evaluation(env = env.env, gamma = 1, v = V)\n",
    "# policy_estimate = action_selection(Q)\n",
    "# render(env, policy_estimate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Model free RL algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.1 Q-Learning\n",
    "Edit the function QLearning in ./RLalgs/ql.py to implement the Q-Learning Algorithm.<br />\n",
    "<span style=\"color:red\">(10 pts)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action values:\n",
      "[[0.03229941 0.03117196 0.0895214  0.01800761]\n",
      " [0.01652987 0.02297582 0.01339944 0.08623094]\n",
      " [0.01440897 0.10727688 0.02606592 0.03224799]\n",
      " [0.04838255 0.00935996 0.00461566 0.00877467]\n",
      " [0.11690654 0.02675449 0.03866131 0.01607612]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.02160439 0.09286479 0.15024422 0.0133821 ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.01757901 0.03463291 0.13027929 0.02953351]\n",
      " [0.00577849 0.09422317 0.21170581 0.05025666]\n",
      " [0.1183065  0.20557358 0.29242444 0.06210585]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.03433271 0.42033978 0.07996462 0.08725914]\n",
      " [0.25402458 0.19705292 0.6450176  0.39895845]\n",
      " [0.         0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "from RLalgs.ql import QLearning\n",
    "Q = QLearning(env = env.env, num_episodes = 1000, gamma = 1, lr = 0.1, e = 0.1)\n",
    "print('Action values:')\n",
    "print(Q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generally, you should get non-zero action values on non-terminal states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# #Uncomment the following to evaluate your result, comment them when you generate the pdf\n",
    "# env = gym.make('FrozenLake-v0')\n",
    "# policy_estimate = action_selection(Q)\n",
    "# render(env, policy_estimate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.2 SARSA\n",
    "Edit the function SARSA in ./RLalgs/sarsa.py to implement the SARSA Algorithm.<br />\n",
    "<span style=\"color:red\">(10 pts)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action values:\n",
      "[[4.78700720e-02 7.79187397e-03 1.41447759e-02 1.08550996e-02]\n",
      " [2.28198987e-03 2.69159956e-02 7.88107263e-06 1.37005959e-02]\n",
      " [7.64905758e-03 5.49238502e-02 2.52045224e-02 5.86969620e-03]\n",
      " [7.10614470e-03 2.64366600e-02 1.97489269e-05 1.36398510e-02]\n",
      " [3.13009756e-02 5.35716707e-02 2.61655581e-02 1.36053301e-02]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [1.58402939e-01 3.52855626e-02 1.72397200e-02 1.12128039e-03]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [2.31259741e-02 8.80161471e-02 4.27523349e-02 1.58388755e-01]\n",
      " [3.12303314e-02 3.14248243e-01 1.71253001e-01 8.10461534e-02]\n",
      " [3.65269282e-01 1.89980484e-01 2.39065067e-02 8.19695213e-02]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [1.03416746e-01 2.52383782e-01 5.79420622e-01 1.25287704e-01]\n",
      " [2.98616723e-01 8.42418764e-01 3.76998320e-01 3.00101991e-01]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "from RLalgs.sarsa import SARSA\n",
    "Q = SARSA(env = env.env, num_episodes = 1000, gamma = 1, lr = 0.1, e = 0.1)\n",
    "print('Action values:')\n",
    "print(Q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generally, you should get non-zero action values on non-terminal states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uncomment the following to evaluate your result, comment them when you generate the pdf\n",
    "# env = gym.make('FrozenLake-v0')\n",
    "# policy_estimate = action_selection(Q)\n",
    "# render(env, policy_estimate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Human\n",
    "You can play this game if you are interested. See if you can get the frisbee either with or without the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from RLalgs.utils import human_play\n",
    "#Uncomment and run the following to play the game, comment it when you generate the pdf\n",
    "# env = gym.make('FrozenLake-v0')\n",
    "# human_play(env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Exploration VS. Exploitation\n",
    "Try to reproduce Figure 2.2 (the upper one is enough) of the Sutton's book based on the experiment described in Chapter 2.3.<br />\n",
    "<span style=\"color:red\">Extra credit (3 pts)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do the experiment and record average reward acquired in each time step\n",
    "############################\n",
    "# YOUR CODE STARTS HERE\n",
    "\n",
    "# YOUR CODE ENDS HERE\n",
    "############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the average reward\n",
    "############################\n",
    "# YOUR CODE STARTS HERE\n",
    "\n",
    "# YOUR CODE ENDS HERE\n",
    "############################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should get curves similar to that in the book."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
